{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "galpyWarning: A major change in versions > 1.1 is that all galpy.potential functions and methods take the potential as the first argument; previously methods such as evaluatePotentials, evaluateDensities, etc. would be called with (R,z,Pot), now they are called as (Pot,R,z) for greater consistency across the codebase\n",
      "galpyWarning: actionAngleAdiabatic_c extension module not loaded, because of error '/home/extmilan/anaconda3/lib/python3.6/site-packages/galpy-1.3.dev0-py3.6-linux-x86_64.egg/galpy_actionAngle_c.cpython-36m-x86_64-linux-gnu.so: undefined symbol: gsl_integration_glfixed_table_alloc' \n",
      "galpyWarning: actionAngleStaeckel_c extension module not loaded, because of error '/home/extmilan/anaconda3/lib/python3.6/site-packages/galpy-1.3.dev0-py3.6-linux-x86_64.egg/galpy_actionAngle_c.cpython-36m-x86_64-linux-gnu.so: undefined symbol: gsl_integration_glfixed_table_alloc' \n",
      "galpyWarning: actionAngleTorus_c extension module not loaded, because galpy_actionAngleTorus_c.cpython-36m-x86_64-linux-gnu.so image was not found\n"
     ]
    }
   ],
   "source": [
    "from galpy.potential import MiyamotoNagaiPotential, NFWPotential, HernquistPotential\n",
    "from galpy.actionAngle import estimateDeltaStaeckel, actionAngleStaeckel\n",
    "from galpy.actionAngle import UnboundError\n",
    "\n",
    "from areposnap.gadget import gadget_readsnap\n",
    "from areposnap.gadget_subfind import load_subfind\n",
    "\n",
    "from auriga_basics import *\n",
    "from auriga_functions import *\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import corner\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import copy\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib import animation\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "cmap = copy.copy(plt.cm.inferno)\n",
    "cmap.set_bad((0,0,0))\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level   : 4\n",
      "halo    : 24\n",
      "snapnr  : 127\n",
      "basedir : /hits/universe/GigaGalaxy/level4_MHD/\n",
      "halodir : /hits/universe/GigaGalaxy/level4_MHD/halo_24/\n",
      "snappath: /hits/universe/GigaGalaxy/level4_MHD/halo_24/output/\n",
      "\n",
      "[ 34.42281723  33.16259384  37.29567337]\n",
      "Found 1783163 stars.\n",
      "Rotated pos.\n",
      "Rotated vel.\n",
      "\n",
      "galrad  : 0.02408556640148163\n",
      "redshift: 2.220446049250313e-16\n",
      "time    : 0.9999999999999998\n",
      "center  : [ 0.  0.  0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simulation relevant stuff\n",
    "machine = 'mac'\n",
    "machine = 'magny'\n",
    "\n",
    "if machine == 'magny':\n",
    "    filedir = \"/home/extmilan/masterthesis/files/\"\n",
    "    basedir = \"/hits/universe/GigaGalaxy/level4_MHD/\"\n",
    "    plotdir = \"/home/extmilan/masterthesis/plots/\"\n",
    "elif machine == 'mac':\n",
    "    filedir = \"/Users/smilanov/Documents/masterthesis/auriga_files/files/\"\n",
    "    basedir = \"/Users/smilanov/Desktop/Auriga/level4/\"\n",
    "    plotdir = \"/Users/smilanov/Documents/masterthesis/auriga_files/plots/\"\n",
    "else:\n",
    "    raise NotADirectoryError\n",
    "    \n",
    "#### path = /hits/universe/GigaGalaxy/level4_MHD/halo_24/output/*\n",
    "level = 4\n",
    "\n",
    "for halo_number in [24]:  # range(1, 31):\n",
    "    halodir = basedir+\"halo_{0}/\".format(halo_number)\n",
    "    snappath = halodir+\"output/\"\n",
    "\n",
    "    for snapnr in range(127,128,1):\n",
    "        print(\"level   : {0}\".format(level))\n",
    "        print(\"halo    : {0}\".format(halo_number))\n",
    "        print(\"snapnr  : {0}\".format(snapnr))\n",
    "        print(\"basedir : {0}\".format(basedir))\n",
    "        print(\"halodir : {0}\".format(halodir))\n",
    "        print(\"snappath: {0}\\n\".format(snappath))\n",
    "        s, sf = eat_snap_and_fof(level, halo_number, snapnr, snappath, loadonlytype=[4], \n",
    "            haloid=0, galradfac=0.1, verbose=True) \n",
    "\n",
    "        # Clean negative and zero values of gmet to avoid RuntimeErrors\n",
    "        # later on (e.g. dividing by zero)\n",
    "        s.data['gmet'] = np.maximum( s.data['gmet'], 1e-40 )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Snapshot =  127\n",
    "v0_tot_kms at R0_kpc = 8.02852213383 : 220.724646624\n",
    "Stellar Disk - a_MND_kpc = 2.96507719743 b_MND_kpc = 1.63627757204 v0_MND_kms = 105.005287928\n",
    "Stellar Spheroid - a_HB_kp c= 1.71545528287 v0_HB_kms = 111.241910552\n",
    "DM Halo - a_NFWH_kpc = 26.0152749345 v0_NFWH_kms = 159.117869741\n",
    "\"\"\"\n",
    "\n",
    "fix_v0_kms      = 220.724646624\n",
    "fix_R0_kpc      = 8.02852213383\n",
    "fix_a_MND_kpc   = 2.96507719743\n",
    "fix_b_MND_kpc   = 1.63627757204\n",
    "fix_v0_MND_kms  = 105.005287928\n",
    "fix_a_HB_kpc    = 1.71545528287\n",
    "fix_v0_HB_kms   = 111.241910552\n",
    "fix_v0_NFWH_kms = 159.117869741\n",
    "init_a_NFWH_kpc = 26.0152749345\n",
    "\n",
    "fix_n_MND       = fix_v0_MND_kms**2  / fix_v0_kms**2\n",
    "fix_n_HB        = fix_v0_HB_kms**2   / fix_v0_kms**2\n",
    "fix_n_NFWH      = fix_v0_NFWH_kms**2 / fix_v0_kms**2\n",
    "\n",
    "#_____function that sets-up galpy potential_____\n",
    "def setup_galpy_potential(a_MND_kpc, b_MND_kpc, a_NFWH_kpc, a_HB_kpc, n_MND, n_NFWH, n_HB, _REFR0_kpc):\n",
    "    \n",
    "    #test input:\n",
    "    if (a_MND_kpc <= 0.) or (b_MND_kpc <= 0.) or (a_NFWH_kpc <= 0.) or (a_HB_kpc <= 0.) \\\n",
    "       or (n_MND <= 0.) or (n_NFWH <= 0.) or (n_HB <= 0.) or (n_MND >= 1.) or (n_NFWH >= 1.) or (n_HB >= 1.):\n",
    "        raise ValueError('Error in setup_galpy_potential: '+\\\n",
    "                         'The input parameters for the scaling profiles do not correspond to a physical potential.')\n",
    "    if np.fabs(n_MND + n_NFWH + n_HB - 1.) > 1e-7:\n",
    "        raise ValueError('Error in setup_galpy_potential: '+\\\n",
    "                         'The sum of the normalization does not add up to 1.')\n",
    "        \n",
    "    #trafo to galpy units:\n",
    "    a_MND  = a_MND_kpc  / _REFR0_kpc\n",
    "    b_MND  = b_MND_kpc  / _REFR0_kpc\n",
    "    a_NFWH = a_NFWH_kpc / _REFR0_kpc\n",
    "    a_HB   = a_HB_kpc   / _REFR0_kpc\n",
    "    \n",
    "    #setup potential:\n",
    "    disk = MiyamotoNagaiPotential(\n",
    "                a = a_MND,\n",
    "                b = b_MND,\n",
    "                normalize = n_MND)\n",
    "    halo = NFWPotential(\n",
    "                a = a_NFWH,\n",
    "                normalize = n_NFWH)\n",
    "    bulge = HernquistPotential(\n",
    "                a = a_HB,\n",
    "                normalize = n_HB) \n",
    "     \n",
    "    return [disk,halo,bulge]\n",
    "\n",
    "\n",
    "#for a in range(50):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load GC IDs & create their mask\n",
    "IDs1 = np.loadtxt(filedir + 'surviving_ids_snapshot_67_sh_1.txt')\n",
    "gcmask1 = np.isin(s.id, IDs1)\n",
    "IDs2 = np.loadtxt(filedir + 'surviving_ids_snapshot_73_sh_1.txt')\n",
    "gcmask2 = np.isin(s.id, IDs2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:42:35.694448\n",
      "0\n",
      "11:43:23.622098\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    if i == 0:\n",
    "        gcmask = gcmask1\n",
    "        IDs = IDs1\n",
    "    elif i == 1:\n",
    "        gcmask = gcmask2\n",
    "        IDs = IDs2\n",
    "    ### for \"true\" a_NFWH\n",
    "    # set up galpy potential with values of potential fitting (either smoothed or not, depends on commenting out or not)\n",
    "    pot_galpy = setup_galpy_potential(fix_a_MND_kpc, fix_b_MND_kpc, init_a_NFWH_kpc, fix_a_HB_kpc, fix_n_MND, fix_n_NFWH, fix_n_HB, fix_R0_kpc)\n",
    "\n",
    "    # this would mean that there are no merged GCs\n",
    "    if np.sum(gcmask) == 0:\n",
    "        print(\"skipped this step\")\n",
    "        #continue\n",
    "\n",
    "    # get position and velocities of all selected GCs & convert to galpy units\n",
    "    (R_kpc, phi_rad, z_kpc), (vR_kms, vphi_kms, vz_kms) = get_cylindrical_vectors(s, sf, gcmask)\n",
    "    # convert physical to galpy units by dividing by REF vals (get velocities from best fit parameters)\n",
    "    R_galpy, vR_galpy, vT_galpy, z_galpy, vz_galpy = R_kpc / fix_R0_kpc, vR_kms / fix_v0_kms, vphi_kms / fix_v0_kms, z_kpc / fix_R0_kpc, vz_kms / fix_v0_kms\n",
    "\n",
    "    # estimate Delta of the Staeckel potential\n",
    "    delta = 0.45\n",
    "    delta = estimateDeltaStaeckel(pot_galpy, R_galpy, z_galpy)\n",
    "    # CHECK HOW BIG INFLUENCE OF DELTA IS\n",
    "\n",
    "\n",
    "    # set up the actionAngleStaeckel object\n",
    "    aAS = actionAngleStaeckel(\n",
    "            pot   = pot_galpy,  # potential\n",
    "            delta = delta,      # focal length of confocal coordinate system\n",
    "            c     = True        # use C code (for speed)\n",
    "            )\n",
    "\n",
    "\n",
    "    jR_galpy, lz_galpy, jz_galpy, r_kpc = np.zeros(len(IDs)), np.zeros(len(IDs)), np.zeros(len(IDs)), np.zeros(len(IDs))\n",
    "    savedIDs = np.zeros(len(IDs))\n",
    "    IDs_notworking = []\n",
    "    for test_i, item in enumerate(IDs):\n",
    "        if (test_i % 1000) == 0:\n",
    "            print(datetime.datetime.now().time())\n",
    "            print(test_i)\n",
    "        try: \n",
    "            jR_galpy[test_i], lz_galpy[test_i], jz_galpy[test_i] = aAS(R_galpy[test_i], vR_galpy[test_i], vT_galpy[test_i], z_galpy[test_i], vz_galpy[test_i])\n",
    "            r_kpc[test_i] = np.sqrt(R_kpc[test_i]**2 + z_kpc[test_i]**2)\n",
    "            savedIDs[test_i] = item\n",
    "        except(ValueError, UnboundError):\n",
    "            IDs_notworking.append(item)\n",
    "            continue\n",
    "    print('numbers of GCs wo actions:', len(IDs_notworking))\n",
    "    jR_kpckms, lz_kpckms, jz_kpckms = jR_galpy * fix_R0_kpc * fix_v0_kms, lz_galpy * fix_R0_kpc * fix_v0_kms, jz_galpy * fix_R0_kpc * fix_v0_kms\n",
    "\n",
    "    # just pick result values of particles of which I actually could calculate actions\n",
    "    survivor_id_mask = np.isin(IDs, savedIDs)\n",
    "    jR_kpckms, lz_kpckms, jz_kpckms = jR_kpckms[survivor_id_mask], lz_kpckms[survivor_id_mask], jz_kpckms[survivor_id_mask]\n",
    "    r_kpc = r_kpc[survivor_id_mask]\n",
    "    survivor_IDs = IDs[survivor_id_mask]\n",
    "    init_jR_kpckms = jR_kpckms\n",
    "    init_jz_kpckms = jz_kpckms\n",
    "    \n",
    "    init_mean_jR_kpckms = np.mean(jR_kpckms)\n",
    "    init_std_jR_kpckms  = np.std(jR_kpckms)\n",
    "    init_skew_jR_kpckms = stats.skew(jR_kpckms)\n",
    "    init_mean_jz_kpckms = np.mean(jz_kpckms)\n",
    "    init_std_jz_kpckms  = np.std(jz_kpckms)\n",
    "    init_skew_jz_kpckms = stats.skew(jz_kpckms)\n",
    "    init_cov_jR_jz = np.cov(jR_kpckms, jz_kpckms)\n",
    "    init_mean_lz_kpckms = np.mean(lz_kpckms)\n",
    "\n",
    "    test_widths = np.arange(150,1100,50)\n",
    "    for test_width in test_widths:\n",
    "        #test_width = 150.\n",
    "        test_step = test_width / 2.\n",
    "\n",
    "        cond_jR = np.where((jR_kpckms < (init_mean_jR_kpckms + test_step)) & (jR_kpckms > (init_mean_jR_kpckms - test_step)))\n",
    "        cond_lz = np.where((lz_kpckms < (init_mean_lz_kpckms + test_step)) & (lz_kpckms > (init_mean_lz_kpckms - test_step)))\n",
    "        cond_jz = np.where((jz_kpckms < (init_mean_jz_kpckms + test_step)) & (jz_kpckms > (init_mean_jz_kpckms - test_step)))\n",
    "\n",
    "\n",
    "        jR_gcmask = np.isin(s.id, IDs[cond_jR])\n",
    "        lz_gcmask = np.isin(s.id, IDs[cond_lz])\n",
    "        jz_gcmask = np.isin(s.id, IDs[cond_jz])\n",
    "\n",
    "        i_test_GCs = jR_gcmask * lz_gcmask * jz_gcmask\n",
    "\n",
    "\n",
    "        print(\"number of GCs within test width = {} kpc/km/s: {}\".format(test_width, np.sum(i_test_GCs)))\n",
    "    if i == 0:\n",
    "        test_width = 1050.\n",
    "    elif i == 1:\n",
    "        test_width = 550.\n",
    "    ### for \"false\" a_NFWH\n",
    "    #N = 50\n",
    "\n",
    "    from matplotlib.patches import Ellipse\n",
    "\n",
    "    def eigsorted(cov):\n",
    "        vals, vecs = np.linalg.eigh(cov)\n",
    "        order = vals.argsort()[::-1]\n",
    "        return vals[order], vecs[:,order]\n",
    "\n",
    "    \n",
    "    test_step = test_width / 2.\n",
    "\n",
    "    cond_jR = np.where((jR_kpckms < (init_mean_jR_kpckms + test_step)) & (jR_kpckms > (init_mean_jR_kpckms - test_step)))\n",
    "    cond_lz = np.where((lz_kpckms < (init_mean_lz_kpckms + test_step)) & (lz_kpckms > (init_mean_lz_kpckms - test_step)))\n",
    "    cond_jz = np.where((jz_kpckms < (init_mean_jz_kpckms + test_step)) & (jz_kpckms > (init_mean_jz_kpckms - test_step)))\n",
    "\n",
    "\n",
    "    jR_gcmask = np.isin(s.id, IDs[cond_jR])\n",
    "    lz_gcmask = np.isin(s.id, IDs[cond_lz])\n",
    "    jz_gcmask = np.isin(s.id, IDs[cond_jz])\n",
    "\n",
    "    i_test_GCs = jR_gcmask * lz_gcmask * jz_gcmask\n",
    "\n",
    "    jR_lz_intersect = np.intersect1d(IDs[cond_jR], IDs[cond_lz])\n",
    "    jR_lz_jz_intersect = np.intersect1d(jR_lz_intersect, IDs[cond_jz])\n",
    "\n",
    "    num_GCs = np.sum(i_test_GCs)\n",
    "    #IDs_all = IDs\n",
    "    print(num_GCs, jR_lz_jz_intersect)\n",
    "    used_IDs = jR_lz_jz_intersect\n",
    "\n",
    "    a_NFWH_arr = np.arange(10,41,1)\n",
    "    if i == 0:\n",
    "        mean_jR_kpckms0 = []\n",
    "        std_jR_kpckms0  = []\n",
    "        skew_jR_kpckms0 = []\n",
    "        mean_jz_kpckms0 = []\n",
    "        std_jz_kpckms0  = []\n",
    "        skew_jz_kpckms0 = []\n",
    "        covs_jR_jz0 = []\n",
    "    elif i ==1:\n",
    "        mean_jR_kpckms1 = []\n",
    "        std_jR_kpckms1  = []\n",
    "        skew_jR_kpckms1 = []\n",
    "        mean_jz_kpckms1 = []\n",
    "        std_jz_kpckms1  = []\n",
    "        skew_jz_kpckms1 = []\n",
    "        covs_jR_jz1 = []\n",
    "    for var_a_NFW_kpc in a_NFWH_arr:\n",
    "        print(\"a_NFW = {}\".format(var_a_NFW_kpc))\n",
    "        # set up galpy potential with values of potential fitting (either smoothed or not, depends on commenting out or not)\n",
    "        try:\n",
    "            pot_galpy = setup_galpy_potential(fix_a_MND_kpc, fix_b_MND_kpc, var_a_NFW_kpc, fix_a_HB_kpc, fix_n_MND, fix_n_NFWH, fix_n_HB, fix_R0_kpc)\n",
    "        except:\n",
    "            if i == 0:\n",
    "                mean_jR_kpckms0.append(-99.)\n",
    "                std_jR_kpckms0.append(-99.)\n",
    "                mean_lz_kpckms0.append(-99.)\n",
    "                std_lz_kpckms0.append(-99.)\n",
    "                mean_jz_kpckms0.append(-99.)\n",
    "                std_jz_kpckms0.append(-99.)\n",
    "            elif i == 1:\n",
    "                mean_jR_kpckms1.append(-99.)\n",
    "                std_jR_kpckms1.append(-99.)\n",
    "                mean_lz_kpckms1.append(-99.)\n",
    "                std_lz_kpckms1.append(-99.)\n",
    "                mean_jz_kpckms1.append(-99.)\n",
    "                std_jz_kpckms1.append(-99.)\n",
    "            print('For a_NFW = {:d} no potential can be set up.'.format(var_a_NFW_kpc) )\n",
    "            continue\n",
    "        # this would mean that there are no merged GCs\n",
    "        if np.sum(i_test_GCs) == 0:\n",
    "            print(\"skipped this step\")\n",
    "            #continue\n",
    "\n",
    "        # get position and velocities of all selected GCs & convert to galpy units\n",
    "        (R_kpc, phi_rad, z_kpc), (vR_kms, vphi_kms, vz_kms) = get_cylindrical_vectors(s, sf, i_test_GCs)\n",
    "        # convert physical to galpy units by dividing by REF vals (get velocities from best fit parameters)\n",
    "        R_galpy, vR_galpy, vT_galpy, z_galpy, vz_galpy = R_kpc / fix_R0_kpc, vR_kms / fix_v0_kms, vphi_kms / fix_v0_kms, z_kpc / fix_R0_kpc, vz_kms / fix_v0_kms\n",
    "\n",
    "        # estimate Delta of the Staeckel potential\n",
    "        delta = 0.45\n",
    "        delta = estimateDeltaStaeckel(pot_galpy, R_galpy, z_galpy)\n",
    "        # CHECK HOW BIG INFLUENCE OF DELTA IS\n",
    "\n",
    "\n",
    "        # set up the actionAngleStaeckel object\n",
    "        aAS = actionAngleStaeckel(\n",
    "                pot   = pot_galpy,  # potential\n",
    "                delta = delta,      # focal length of confocal coordinate system\n",
    "                c     = True        # use C code (for speed)\n",
    "                )\n",
    "\n",
    "\n",
    "        jR_galpy, lz_galpy, jz_galpy, r_kpc = np.zeros(num_GCs), np.zeros(num_GCs), np.zeros(num_GCs), np.zeros(num_GCs)\n",
    "        savedIDs = np.zeros(num_GCs)\n",
    "        IDs_notworking = []\n",
    "\n",
    "\n",
    "        for test_i, item in enumerate(used_IDs):\n",
    "            '''        \n",
    "            if (test_i % 1000) == 0:\n",
    "                print(datetime.datetime.now().time())\n",
    "                print(test_i)\n",
    "            '''\n",
    "            try: \n",
    "                jR_galpy[test_i], lz_galpy[test_i], jz_galpy[test_i] = aAS(R_galpy[test_i], vR_galpy[test_i], vT_galpy[test_i], z_galpy[test_i], vz_galpy[test_i])\n",
    "                r_kpc[test_i] = np.sqrt(R_kpc[test_i]**2 + z_kpc[test_i]**2)\n",
    "                savedIDs[test_i] = item\n",
    "            except(ValueError, UnboundError):\n",
    "                IDs_notworking.append(item)\n",
    "                continue\n",
    "        print('numbers of GCs wo actions:', len(IDs_notworking))\n",
    "        jR_kpckms, lz_kpckms, jz_kpckms = jR_galpy * fix_R0_kpc * fix_v0_kms, lz_galpy * fix_R0_kpc * fix_v0_kms, jz_galpy * fix_R0_kpc * fix_v0_kms\n",
    "\n",
    "        # just pick result values of particles of which I actually could calculate actions\n",
    "        survivor_id_mask = np.isin(used_IDs, savedIDs)\n",
    "        jR_kpckms, lz_kpckms, jz_kpckms = jR_kpckms[survivor_id_mask], lz_kpckms[survivor_id_mask], jz_kpckms[survivor_id_mask]\n",
    "        r_kpc = r_kpc[survivor_id_mask]\n",
    "        survivor_IDs = used_IDs[survivor_id_mask]\n",
    "\n",
    "        if i ==0:\n",
    "            mean_jR_kpckms0.append(np.mean(jR_kpckms))\n",
    "            std_jR_kpckms0.append(np.std(jR_kpckms))\n",
    "            skew_jR_kpckms0.append(stats.skew(jR_kpckms))\n",
    "            mean_jz_kpckms0.append(np.mean(jz_kpckms))\n",
    "            std_jz_kpckms0.append(np.std(jz_kpckms))\n",
    "            skew_jz_kpckms0.append(stats.skew(jz_kpckms))\n",
    "            cov_jR_jz = np.cov(jR_kpckms, jz_kpckms)\n",
    "            covs_jR_jz0.append(cov_jR_jz)\n",
    "        elif i ==1:\n",
    "            mean_jR_kpckms1.append(np.mean(jR_kpckms))\n",
    "            std_jR_kpckms1.append(np.std(jR_kpckms))\n",
    "            skew_jR_kpckms1.append(stats.skew(jR_kpckms))\n",
    "            mean_jz_kpckms1.append(np.mean(jz_kpckms))\n",
    "            std_jz_kpckms1.append(np.std(jz_kpckms))\n",
    "            skew_jz_kpckms1.append(stats.skew(jz_kpckms))\n",
    "            cov_jR_jz = np.cov(jR_kpckms, jz_kpckms)\n",
    "            covs_jR_jz1.append(cov_jR_jz)            \n",
    "        '''\n",
    "        nstd = 2\n",
    "        ax = plt.subplot(111)\n",
    "\n",
    "        #cov = np.cov(x, y)\n",
    "        vals, vecs = eigsorted(cov_jR_jz)\n",
    "        theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "        w, h = 2 * nstd * np.sqrt(vals)\n",
    "        ell = Ellipse(xy=(np.mean(jR_kpckms), np.mean(jz_kpckms)),\n",
    "                      width=w, height=h,\n",
    "                      angle=theta, color='black')\n",
    "        ell.set_facecolor('none')\n",
    "        ax.add_artist(ell)\n",
    "        plt.hist2d(jR_kpckms, jz_kpckms, bins = 5)\n",
    "        plt.xlabel('jR [kpc/km/s]')\n",
    "        plt.ylabel('jz [kpc/km/s]')\n",
    "        plt.show()\n",
    "        '''\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize = (15,10))\n",
    "\n",
    "ax1.plot(a_NFWH_arr, std_jR_kpckms0, marker = '.', color = 'black', linestyle = None, label = 'early merger')\n",
    "ax1.plot(a_NFWH_arr, std_jR_kpckms1, marker = '.', color = 'blue', linestyle = None, label = 'late merger')\n",
    "\n",
    "ax1.plot(init_a_NFWH_kpc, init_std_jR_kpckms, marker = '+', color = 'red')\n",
    "#ax1.xlabel('a$_{NFW}$')\n",
    "#ax1.set_yscale(\"log\", nonposy='clip')\n",
    "#ax1.hlines(init_mean_jR_kpckms, 0, np.max(a_NFWH_arr)+1, color = 'red', alpha = 0.5)\n",
    "#ax1.set_ylim(10, None)\n",
    "ax1.legend()\n",
    "\n",
    "ax1.set_ylabel('std j$_R$ [kpc/km/s]', size = 'x-large')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "ax2.plot(a_NFWH_arr, std_jz_kpckms0, marker = '.', color = 'black', label = 'early merger')\n",
    "ax2.plot(a_NFWH_arr, std_jz_kpckms1, marker = '.', color = 'blue', label = 'late merger')\n",
    "ax2.plot(init_a_NFWH_kpc, init_std_jz_kpckms, marker = '+', color = 'red')\n",
    "#ax2.hlines(init_mean_jz_kpckms, 0, np.max(a_NFWH_arr)+1, color = 'red', alpha = 0.5)\n",
    "\n",
    "ax2.set_xlabel('a$_{NFW}$ [kpc]', size = 'x-large')\n",
    "#ax2.set_yscale(\"log\", nonposy='clip')\n",
    "#ax2.set_ylim(0, None)\n",
    "ax2.set_ylabel('std j$_z$ [kpc/km/s]', size = 'x-large')\n",
    "#plt.show()\n",
    "ax2.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(plotdir + 'a_NFW_67_73_diagnostic_plot_std_small_box.png', dpi = 300, format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "init_mean_jR_kpckms = np.mean(jR_kpckms)\n",
    "init_std_jR_kpckms  = np.std(jR_kpckms)\n",
    "init_skew_jR_kpckms = stats.skew(jR_kpckms)\n",
    "init_mean_jz_kpckms = np.mean(jz_kpckms)\n",
    "init_std_jz_kpckms  = np.std(jz_kpckms)\n",
    "init_skew_jz_kpckms = stats.skew(jz_kpckms)\n",
    "init_cov_jR_jz = np.cov(jR_kpckms, jz_kpckms)\n",
    "init_mean_lz_kpckms = np.mean(lz_kpckms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_widths = np.arange(150,1050,50)\n",
    "for test_width in test_widths:\n",
    "    #test_width = 150.\n",
    "    test_step = test_width / 2.\n",
    "\n",
    "    cond_jR = np.where((jR_kpckms < (init_mean_jR_kpckms + test_step)) & (jR_kpckms > (init_mean_jR_kpckms - test_step)))\n",
    "    cond_lz = np.where((lz_kpckms < (init_mean_lz_kpckms + test_step)) & (lz_kpckms > (init_mean_lz_kpckms - test_step)))\n",
    "    cond_jz = np.where((jz_kpckms < (init_mean_jz_kpckms + test_step)) & (jz_kpckms > (init_mean_jz_kpckms - test_step)))\n",
    "\n",
    "\n",
    "    jR_gcmask = np.isin(s.id, IDs[cond_jR])\n",
    "    lz_gcmask = np.isin(s.id, IDs[cond_lz])\n",
    "    jz_gcmask = np.isin(s.id, IDs[cond_jz])\n",
    "\n",
    "    i_test_GCs = jR_gcmask * lz_gcmask * jz_gcmask\n",
    "\n",
    "\n",
    "    print(\"number of GCs within test width = {} kpc/km/s: {}\".format(test_width, np.sum(i_test_GCs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### for \"false\" a_NFWH\n",
    "#N = 50\n",
    "\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def eigsorted(cov):\n",
    "    vals, vecs = np.linalg.eigh(cov)\n",
    "    order = vals.argsort()[::-1]\n",
    "    return vals[order], vecs[:,order]\n",
    "\n",
    "test_width = 1000.\n",
    "test_step = test_width / 2.\n",
    "\n",
    "cond_jR = np.where((jR_kpckms < (init_mean_jR_kpckms + test_step)) & (jR_kpckms > (init_mean_jR_kpckms - test_step)))\n",
    "cond_lz = np.where((lz_kpckms < (init_mean_lz_kpckms + test_step)) & (lz_kpckms > (init_mean_lz_kpckms - test_step)))\n",
    "cond_jz = np.where((jz_kpckms < (init_mean_jz_kpckms + test_step)) & (jz_kpckms > (init_mean_jz_kpckms - test_step)))\n",
    "\n",
    "\n",
    "jR_gcmask = np.isin(s.id, IDs[cond_jR])\n",
    "lz_gcmask = np.isin(s.id, IDs[cond_lz])\n",
    "jz_gcmask = np.isin(s.id, IDs[cond_jz])\n",
    "\n",
    "i_test_GCs = jR_gcmask * lz_gcmask * jz_gcmask\n",
    "\n",
    "jR_lz_intersect = np.intersect1d(IDs[cond_jR], IDs[cond_lz])\n",
    "jR_lz_jz_intersect = np.intersect1d(jR_lz_intersect, IDs[cond_jz])\n",
    "\n",
    "num_GCs = np.sum(i_test_GCs)\n",
    "#IDs_all = IDs\n",
    "print(num_GCs, jR_lz_jz_intersect)\n",
    "used_IDs = jR_lz_jz_intersect\n",
    "\n",
    "a_NFWH_arr = np.arange(10,41,1)\n",
    "mean_jR_kpckms = []\n",
    "std_jR_kpckms  = []\n",
    "skew_jR_kpckms = []\n",
    "mean_jz_kpckms = []\n",
    "std_jz_kpckms  = []\n",
    "skew_jz_kpckms = []\n",
    "covs_jR_jz = []\n",
    "for var_a_NFW_kpc in a_NFWH_arr:\n",
    "    print(\"a_NFW = {}\".format(var_a_NFW_kpc))\n",
    "    # set up galpy potential with values of potential fitting (either smoothed or not, depends on commenting out or not)\n",
    "    try:\n",
    "        pot_galpy = setup_galpy_potential(fix_a_MND_kpc, fix_b_MND_kpc, var_a_NFW_kpc, fix_a_HB_kpc, fix_n_MND, fix_n_NFWH, fix_n_HB, fix_R0_kpc)\n",
    "    except:\n",
    "        mean_jR_kpckms.append(-99.)\n",
    "        std_jR_kpckms.append(-99.)\n",
    "        mean_lz_kpckms.append(-99.)\n",
    "        std_lz_kpckms.append(-99.)\n",
    "        mean_jz_kpckms.append(-99.)\n",
    "        std_jz_kpckms.append(-99.)\n",
    "        print('For a_NFW = {:d} no potential can be set up.'.format(var_a_NFW_kpc) )\n",
    "        continue\n",
    "    # this would mean that there are no merged GCs\n",
    "    if np.sum(i_test_GCs) == 0:\n",
    "        print(\"skipped this step\")\n",
    "        #continue\n",
    "\n",
    "    # get position and velocities of all selected GCs & convert to galpy units\n",
    "    (R_kpc, phi_rad, z_kpc), (vR_kms, vphi_kms, vz_kms) = get_cylindrical_vectors(s, sf, i_test_GCs)\n",
    "    # convert physical to galpy units by dividing by REF vals (get velocities from best fit parameters)\n",
    "    R_galpy, vR_galpy, vT_galpy, z_galpy, vz_galpy = R_kpc / fix_R0_kpc, vR_kms / fix_v0_kms, vphi_kms / fix_v0_kms, z_kpc / fix_R0_kpc, vz_kms / fix_v0_kms\n",
    "\n",
    "    # estimate Delta of the Staeckel potential\n",
    "    delta = 0.45\n",
    "    delta = estimateDeltaStaeckel(pot_galpy, R_galpy, z_galpy)\n",
    "    # CHECK HOW BIG INFLUENCE OF DELTA IS\n",
    "\n",
    "\n",
    "    # set up the actionAngleStaeckel object\n",
    "    aAS = actionAngleStaeckel(\n",
    "            pot   = pot_galpy,  # potential\n",
    "            delta = delta,      # focal length of confocal coordinate system\n",
    "            c     = True        # use C code (for speed)\n",
    "            )\n",
    "\n",
    "\n",
    "    jR_galpy, lz_galpy, jz_galpy, r_kpc = np.zeros(num_GCs), np.zeros(num_GCs), np.zeros(num_GCs), np.zeros(num_GCs)\n",
    "    savedIDs = np.zeros(num_GCs)\n",
    "    IDs_notworking = []\n",
    "\n",
    "\n",
    "    for test_i, item in enumerate(used_IDs):\n",
    "        '''        \n",
    "        if (test_i % 1000) == 0:\n",
    "            print(datetime.datetime.now().time())\n",
    "            print(test_i)\n",
    "        '''\n",
    "        try: \n",
    "            jR_galpy[test_i], lz_galpy[test_i], jz_galpy[test_i] = aAS(R_galpy[test_i], vR_galpy[test_i], vT_galpy[test_i], z_galpy[test_i], vz_galpy[test_i])\n",
    "            r_kpc[test_i] = np.sqrt(R_kpc[test_i]**2 + z_kpc[test_i]**2)\n",
    "            savedIDs[test_i] = item\n",
    "        except(ValueError, UnboundError):\n",
    "            IDs_notworking.append(item)\n",
    "            continue\n",
    "    print('numbers of GCs wo actions:', len(IDs_notworking))\n",
    "    jR_kpckms, lz_kpckms, jz_kpckms = jR_galpy * fix_R0_kpc * fix_v0_kms, lz_galpy * fix_R0_kpc * fix_v0_kms, jz_galpy * fix_R0_kpc * fix_v0_kms\n",
    "\n",
    "    # just pick result values of particles of which I actually could calculate actions\n",
    "    survivor_id_mask = np.isin(used_IDs, savedIDs)\n",
    "    jR_kpckms, lz_kpckms, jz_kpckms = jR_kpckms[survivor_id_mask], lz_kpckms[survivor_id_mask], jz_kpckms[survivor_id_mask]\n",
    "    r_kpc = r_kpc[survivor_id_mask]\n",
    "    survivor_IDs = used_IDs[survivor_id_mask]\n",
    "\n",
    "    if i == 0:\n",
    "    mean_jR_kpckms.append(np.mean(jR_kpckms))\n",
    "    std_jR_kpckms.append(np.std(jR_kpckms))\n",
    "    skew_jR_kpckms.append(stats.skew(jR_kpckms))\n",
    "    mean_jz_kpckms.append(np.mean(jz_kpckms))\n",
    "    std_jz_kpckms.append(np.std(jz_kpckms))\n",
    "    skew_jz_kpckms.append(stats.skew(jz_kpckms))\n",
    "    cov_jR_jz = np.cov(jR_kpckms, jz_kpckms)\n",
    "    covs_jR_jz.append(cov_jR_jz)\n",
    "    \n",
    "    nstd = 2\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    #cov = np.cov(x, y)\n",
    "    vals, vecs = eigsorted(cov_jR_jz)\n",
    "    theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "    w, h = 2 * nstd * np.sqrt(vals)\n",
    "    ell = Ellipse(xy=(np.mean(jR_kpckms), np.mean(jz_kpckms)),\n",
    "                  width=w, height=h,\n",
    "                  angle=theta, color='black')\n",
    "    ell.set_facecolor('none')\n",
    "    ax.add_artist(ell)\n",
    "    plt.hist2d(jR_kpckms, jz_kpckms, bins = 5)\n",
    "    plt.xlabel('jR [kpc/km/s]')\n",
    "    plt.ylabel('jz [kpc/km/s]')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# goal plot\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize = (15,10))\n",
    "\n",
    "ax1.plot(a_NFWH_arr, np.array(skew_jR_kpckms), 'k.')\n",
    "ax1.plot(init_a_NFWH_kpc, init_skew_jR_kpckms, marker = '+', color = 'red')\n",
    "#ax1.xlabel('a$_{NFW}$')\n",
    "ax1.set_yscale(\"log\", nonposy='clip')\n",
    "#ax1.hlines(init_mean_jR_kpckms, 0, np.max(a_NFWH_arr)+1, color = 'red', alpha = 0.5)\n",
    "ax1.set_ylim(1, 10)\n",
    "\n",
    "ax1.set_ylabel('skewness of j$_R$', size = 'x-large')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "ax2.plot(a_NFWH_arr, skew_jz_kpckms, 'k.')\n",
    "ax2.plot(init_a_NFWH_kpc, init_skew_jz_kpckms, marker = '+', color = 'red')\n",
    "#ax2.hlines(init_mean_jz_kpckms, 0, np.max(a_NFWH_arr)+1, color = 'red', alpha = 0.5)\n",
    "\n",
    "ax2.set_xlabel('a$_{NFW}$ [kpc]', size = 'x-large')\n",
    "#ax2.set_yscale(\"log\", nonposy='clip')\n",
    "ax2.set_ylim(1.615, 1.625)\n",
    "ax2.set_ylabel('skewness of j$_z$', size = 'x-large')\n",
    "#plt.show()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(plotdir + 'a_NFW_diagnostic_plot_skewness_small_box.png', dpi = 300, format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(skew_jz_kpckms), np.max(skew_jz_kpckms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize = (15,10))\n",
    "\n",
    "ax1.plot(a_NFWH_arr, std_jR_kpckms, marker = '.', color = 'black', linestyle = None)\n",
    "ax1.plot(init_a_NFWH_kpc, init_std_jR_kpckms, marker = '+', color = 'red')\n",
    "#ax1.xlabel('a$_{NFW}$')\n",
    "#ax1.set_yscale(\"log\", nonposy='clip')\n",
    "#ax1.hlines(init_mean_jR_kpckms, 0, np.max(a_NFWH_arr)+1, color = 'red', alpha = 0.5)\n",
    "#ax1.set_ylim(10, None)\n",
    "\n",
    "ax1.set_ylabel('std j$_R$ [kpc/km/s]', size = 'x-large')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "ax2.plot(a_NFWH_arr,std_jz_kpckms, marker = '.', color = 'black')\n",
    "ax2.plot(init_a_NFWH_kpc, init_std_jz_kpckms, marker = '+', color = 'red')\n",
    "#ax2.hlines(init_mean_jz_kpckms, 0, np.max(a_NFWH_arr)+1, color = 'red', alpha = 0.5)\n",
    "\n",
    "ax2.set_xlabel('a$_{NFW}$ [kpc]', size = 'x-large')\n",
    "#ax2.set_yscale(\"log\", nonposy='clip')\n",
    "#ax2.set_ylim(0, None)\n",
    "ax2.set_ylabel('std j$_z$ [kpc/km/s]', size = 'x-large')\n",
    "#plt.show()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(plotdir + 'a_67_NFW_diagnostic_plot_std_small_box.png', dpi = 300, format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize = (15,10))\n",
    "\n",
    "ax1.errorbar(a_NFWH_arr, np.array(mean_jR_kpckms), yerr = np.array(std_jR_kpckms), marker = '.', color = 'black', linestyle = None)\n",
    "ax1.errorbar(init_a_NFWH_kpc, init_mean_jR_kpckms, init_std_jR_kpckms, marker = '+', color = 'red')\n",
    "#ax1.xlabel('a$_{NFW}$')\n",
    "ax1.set_yscale(\"log\", nonposy='clip')\n",
    "ax1.hlines(init_mean_jR_kpckms, 0, np.max(a_NFWH_arr)+1, color = 'red', alpha = 0.5)\n",
    "ax1.set_ylim(10, None)\n",
    "\n",
    "ax1.set_ylabel('mean j$_R$ [kpc/km/s]', size = 'x-large')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "ax2.errorbar(a_NFWH_arr, mean_jz_kpckms, yerr = std_jz_kpckms, marker = '.', color = 'black')\n",
    "ax2.errorbar(init_a_NFWH_kpc, init_mean_jz_kpckms, init_std_jz_kpckms, marker = '+', color = 'red')\n",
    "ax2.hlines(init_mean_jz_kpckms, 0, np.max(a_NFWH_arr)+1, color = 'red', alpha = 0.5)\n",
    "\n",
    "ax2.set_xlabel('a$_{NFW}$ [kpc]', size = 'x-large')\n",
    "#ax2.set_yscale(\"log\", nonposy='clip')\n",
    "ax2.set_ylim(0, None)\n",
    "ax2.set_ylabel('mean j$_z$ [kpc/km/s]', size = 'x-large')\n",
    "#plt.show()\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(plotdir + 'a_NFW_diagnostic_plot_mean_std_small_box.png', dpi = 300, format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# try to show covariance matrix\n",
    "for i in range(len(covs_jR_jz)):\n",
    "    # plot correlation matrix\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(covs_jR_jz[i], norm = LogNorm())\n",
    "    fig.colorbar(cax)\n",
    "    ax.set_title('a_NFWH = {} kpc'.format(a_NFWH_arr[i]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nstd = 2\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "#cov = np.cov(x, y)\n",
    "vals, vecs = eigsorted(covs_jR_jz[-1])\n",
    "theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "w, h = 2 * nstd * np.sqrt(vals)\n",
    "ell = Ellipse(xy=(mean_jR_kpckms[-1], mean_jz_kpckms[-1]),\n",
    "              width=w, height=h,\n",
    "              angle=theta, color='black')\n",
    "ell.set_facecolor('none')\n",
    "ax.add_artist(ell)\n",
    "plt.hist2d(jR_kpckms, jz_kpckms, bins = 41)\n",
    "plt.xlabel('jR [kpc/km/s]')\n",
    "plt.ylabel('jz [kpc/km/s]')\n",
    "plt.title('a_NFWH = {} kpc'.format(a_NFWH_arr[-1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstd = 2\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "#cov = np.cov(x, y)\n",
    "vals, vecs = eigsorted(init_cov_jR_jz)\n",
    "theta = np.degrees(np.arctan2(*vecs[:,0][::-1]))\n",
    "w, h = 2 * nstd * np.sqrt(vals)\n",
    "ell = Ellipse(xy=(init_mean_jR_kpckms, init_mean_jz_kpckms),\n",
    "              width=w, height=h,\n",
    "              angle=theta, color='black')\n",
    "ell.set_facecolor('none')\n",
    "ax.add_artist(ell)\n",
    "plt.hist2d(init_jR_kpckms, init_jz_kpckms, bins = 41)\n",
    "plt.xlabel('jR [kpc/km/s]')\n",
    "plt.ylabel('jz [kpc/km/s]')\n",
    "plt.title('a_NFWH = {} kpc'.format(init_a_NFWH_kpc))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate concentration\n",
    "M200 = sf.data['fmc2'][0] #M200\n",
    "R200 = sf.data['frc2'][0] #R200\n",
    "a = init_a_NFWH_kpc\n",
    "c = a/R200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
