{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import pynbody\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### AREPOSNAP-UTIL packages ####\n",
    "# in following packages some of the parameters might be useful to change. still have to figure out which\n",
    "\n",
    "# I think areposnap.gadget is mostly to read in data and do some transformation with them... did not find\n",
    "from areposnap.gadget import gadget_readsnap\n",
    "'''\n",
    "def gadget_readsnap( snapshot, snappath=\".\", snapbase=\"snapshot_\", verbose=False, onlyHeader=False, \\\n",
    "chunk=False, loadonly=False, loadonlytype=False, nommap=True, tracer=False,hdf5=True, forcesingleprec=False,\\\n",
    "cosmological=None, loadonlyhalo=-1, subfind=None, species=None, lazy_load=False ):\n",
    "    if (not (os.path.exists( \"%s/%s%03d\" % (snappath, snapbase, snapshot) ) or \\\n",
    "    os.path.exists( \"%s/%s%03d.0\" % (snappath, snapbase, snapshot) ))) and \\\n",
    "    (os.path.exists( \"%s/snapdir_%03d/%s%03d.0\" % (snappath, snapshot, snapbase, snapshot)) \\\n",
    "    or os.path.exists( \"%s/snapdir_%03d/%s%03d.0.hdf5\" % (snappath, snapshot, snapbase, snapshot)) \\\n",
    "    or os.path.exists( \"%s/snapdir_%03d/%s%03d.0.h5\" % (snappath, snapshot, snapbase, snapshot)) ):\n",
    "        snappath += \"/snapdir_%03d/\" % (snapshot)\n",
    "    return gadget_snap.gadget_snapshot( \"%s/%s%03d\" % (snappath, snapbase, snapshot), \\\n",
    "    verbose=verbose, chunk=chunk, loadonly=loadonly, loadonlytype=loadonlytype, nommap=nommap, \\\n",
    "    onlyHeader=onlyHeader, tracer=tracer, hdf5=hdf5, forcesingleprec=forcesingleprec, \\\n",
    "    cosmological=cosmological, loadonlyhalo=loadonlyhalo, subfind=subfind, species=species, lazy_load=lazy_load )\n",
    "'''\n",
    "\n",
    "from areposnap.gadget_subfind import load_subfind\n",
    "'''\n",
    "def load_subfind( id, base=\"fof_subhalo_tab_\", dir=\"\", verbose=False, loadonly=False, \\\n",
    "hdf5=True, forcesingleprec=False, cosmological=None, onlyHeader=False ):\n",
    "    return subfind( id, base, dir, verbose, loadonly=loadonly, hdf5=hdf5, \\\n",
    "    forcesingleprec=forcesingleprec, cosmological=cosmological, onlyHeader=onlyHeader )\n",
    "'''\n",
    "import areposnap.gadget_snap\n",
    "# has some nice parameters inside, do not know how to access them yet. that is what this notebook is for\n",
    "# but is already called by gadget_readsnap... need to figure out how to to access their really nice parameters\n",
    "# figured it out: just certain particle types have certain parameters ... stars do not have that many\n",
    "\n",
    "# some other arepo-snap util functions which might be useful to me; not loading from the snapshots but from other files\n",
    "# loading energies\n",
    "from areposnap.gadget import gadget_readenergy\n",
    "'''\n",
    "def gadget_readenergy(snappath=\"./\"):\n",
    "    \"\"\" convenience function \"\"\"\n",
    "    return gadget_energyfile(snappath)\n",
    "'''\n",
    "\n",
    "# seems to have ang mom inside\n",
    "from areposnap.gadget import gadget_binaryfile\n",
    "'''\n",
    "def gadget_readbinary(snappath=\"./\"):\n",
    "    return gadget_binaryfile(snappath)\n",
    "'''\n",
    "\n",
    "# could be what we need but I have to figure out what exactly it does and what it needs, especially chunknum and treenum\n",
    "from areposnap.gadget_tree import load_tree, load_tree_fof\n",
    "'''\n",
    "def load_tree(chunknum, treenum ,base=\"\", directory=\"\", verbose=False, loadonly=False, hdf5=True):\n",
    "    return tree(chunknum, treenum, base, directory, verbose, loadonly=loadonly, hdf5=hdf5 )\n",
    "\n",
    "def load_tree_fof(id,fof_tree_catalog,base=\"\", directory=\"\", verbose=False, loadonly=False, hdf5=True):\n",
    "\n",
    "    chunknums,treenums,fofID,subhaloID,treeIDs = genfromtxt(fof_tree_catalog,dtype = int,unpack=True,skip_header=2)\n",
    "    index = where(fofID == id)\n",
    "    if verbose:\n",
    "        print( 'number of trees: ',len(index[0]) )\n",
    "    if len(index[0]) == 0:\n",
    "        print( 'no trees found!' )\n",
    "        return None\n",
    "    chunknum = chunknums[index[0][0]]\n",
    "    treenum = treenums[index[0][0]]\n",
    "    treeID = treeIDs[index[0][0]]\n",
    "\n",
    "    return tree(chunknum, treenum, base, directory, verbose, loadonly=loadonly, hdf5=hdf5 ),treeID\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# written by Timo Halbesma (MPA); added some additional comments for better understanding\n",
    "def eat_snap_and_fof(level, halo_number, snapnr, snappath, loadonlytype=[0,1,2,3,4],\n",
    "                     haloid=0, galradfac=0.1, verbose=True):\n",
    "    \"\"\" Method to eat an Auriga snapshot, given a level/halo_number/snapnr.\n",
    "        Subfind has been executed 'on-the-fly', during the simulation run.\n",
    "\n",
    "        @param level: level of the Auriga simulation (3=high, 4='normal' or 5=low).\n",
    "            Level 3/5 only for halo 6, 16 and 24. See Grand+ 2017 for details.\n",
    "            Careful when level != 4 because directories may have different names.\n",
    "        @param halo_number: which Auriga galaxy? See Grand+ 2017 for details.\n",
    "            Should be an integer in range(1, 31)\n",
    "        @param snapnr: which snapshot number? This is an integer, in most cases\n",
    "            in range(1, 128) depending on the number of timesteps of the run.\n",
    "            The last snapshot would then be 127. Snapshots are written at a\n",
    "            certain time, but careful because the variable called time is actually\n",
    "            the cosmological expansion factor a = 1/(1+z). For example, snapnr=127\n",
    "            has s.time = 1, which corresponds to a redshift of ~0. This makes sense\n",
    "            because this is the last snapshot and the last snapshot is written at\n",
    "            redshift zero\n",
    "        @param snappath: full path to the level/halo directory that contains\n",
    "            all of the simulation snapshots\n",
    "        @param loadonlytype: which particle types should be loaded? This should\n",
    "            be a list of integers. If I'm not mistaken, the options are:\n",
    "            0 (gas), 1 (halo), 2 (disk), 3 (bulge), 4 (stars), 5 (black holes).\n",
    "            So to get the dark matter: load particles 1/2/3. In zoom-simulations\n",
    "            particletype 3 may be used for low-resolution particles in the outer\n",
    "            regions and they should not be present in (and contaminating) the\n",
    "            inner region. I'm not too sure of the latter though.\n",
    "        @param haloid: the ID of the SubFind halo. In case you are interested\n",
    "            in the main galaxy in the simulation run: set haloid to zero.\n",
    "            This was a bit confusing to me at first because a zoom-simulation run\n",
    "            of one Auriga galaxy is also referred to as 'halo', see halo_number.\n",
    "        @param galradfac: the radius of the galaxy is often used to make cuts in\n",
    "            the (star) particles. It seems that in general galrad is set to 10%\n",
    "            of the virial radius R200 of the DM halo that the galaxy sits in. The\n",
    "            disk does seem to 'end' at 0.1R200.\n",
    "        @param verbose: boolean to print some information\n",
    "\n",
    "        @return: two-tuple (s, sf) where s is an instance of the gadget_snapshot\n",
    "            class, and sf is an instance of the subfind class. See Arepo-snap-util,\n",
    "            gadget_snap.py respectively gadget_subfind.py \"\"\"\n",
    "\n",
    "    # Eat the subfind friend of friends output\n",
    "    sf = load_subfind(snapnr, dir=snappath)\n",
    "\n",
    "    # Eat the Gadget snapshot\n",
    "    s = gadget_readsnap(snapnr, snappath=snappath, lazy_load=True,\n",
    "        subfind=sf, loadonlytype=loadonlytype)\n",
    "    s.subfind = sf\n",
    "\n",
    "    # Sets s.(sub)halo. This allows selecting the halo, e.g. 0 (main 'Galaxy')\n",
    "    s.calc_sf_indizes(s.subfind)\n",
    "    # Note that selecting the halo now rotates the disk using the principal axis.\n",
    "    # rotate_disk is a general switch which has to be set to True to rotate.\n",
    "    # To then actually do the rotation, do_rotation has to be True as well.\n",
    "    # Within rotate_disk there are three methods to handle the rotation. Choose\n",
    "    # one of them, but see the select_halo method for details.\n",
    "    s.select_halo( s.subfind, haloid=haloid, galradfac=galradfac,\n",
    "        rotate_disk=True, use_principal_axis=True, euler_rotation=False,\n",
    "        use_cold_gas_spin=False, do_rotation=True )\n",
    "\n",
    "    # Sneak some more info into the s instance\n",
    "    s.halo_number = halo_number\n",
    "    s.level = level\n",
    "    s.snapnr = snapnr\n",
    "    s.haloid = haloid\n",
    "\n",
    "    # This means that galrad is 10 % of R200 (200*rho_crit definition)\n",
    "    s.galrad = galradfac * sf.data['frc2'][haloid]  # frc2 = Group_R_Crit200\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\ngalrad  : {0}\".format(s.galrad))\n",
    "        print(\"redshift: {0}\".format(s.redshift))\n",
    "        print(\"time    : {0}\".format(s.time))\n",
    "        print(\"center  : {0}\\n\".format(s.center))\n",
    "\n",
    "    return s, sf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cartesian_vectors(s, sf, mask):\n",
    "    x,  y,  z  = s.pos[::,2][mask], s.pos[::,1][mask], s.pos[::,0][mask]\n",
    "    vx, vy, vz = s.vel[::,2][mask], s.vel[::,1][mask], s.vel[::,0][mask]\n",
    "\n",
    "    # All three expressions for rxyz compute the same thing :-).\n",
    "    # rxyz = numpy.sqrt( x**2 + y**2 + z**2)\n",
    "    # rxyz = numpy.sqrt( (s.pos[mask]**2).sum(axis=1) )\n",
    "    rxyz = s.r()[mask]\n",
    "\n",
    "    # Both expressions for rxy compute the same thing :-).\n",
    "    # rxy = numpy.sqrt( (s.pos[mask][:,1:]**2).sum(axis=1) )\n",
    "    rxy = numpy.sqrt( x**2 + y**2 )\n",
    "\n",
    "    return (x, y, z), (vx, vy, vz), rxyz, rxy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level = 4\n",
    "basedir = \"/Users/smilanov/Desktop/Auriga/level{0}/\".format(level)\n",
    "for halo_number in [24]:  # range(1, 31):\n",
    "    halodir = basedir+\"halo_{0}/\".format(halo_number)\n",
    "    snappath = halodir+\"output/\"\n",
    "    for snapnr in range(127, 128, 1):\n",
    "        print(\"level   : {0}\".format(level))\n",
    "        print(\"halo    : {0}\".format(halo_number))\n",
    "        print(\"snapnr  : {0}\".format(snapnr))\n",
    "        print(\"basedir : {0}\".format(basedir))\n",
    "        print(\"halodir : {0}\".format(halodir))\n",
    "        print(\"snappath: {0}\\n\".format(snappath))\n",
    "\n",
    "        s, sf = eat_snap_and_fof(level, halo_number, snapnr, snappath,\n",
    "            loadonlytype=[1,2,3,4], haloid=0, galradfac=0.1, verbose=True)\n",
    "\n",
    "        # Clean negative and zero values of gmet to avoid RuntimeErrors\n",
    "        # later on (e.g. dividing by zero)\n",
    "        s.data['gmet'] = numpy.maximum( s.data['gmet'], 1e-40 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "com = s.getCenterOfMass()\n",
    "angc = s.getAngularMomentumCore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "s.id should be super useful following a particle through the different snapshots\n",
    "buuut: \n",
    "    find the fastest way to compare a list of subsets to the main Id list (containing more than 4million IDs)\n",
    "    it can happen that some particles are created along the way and not there from the beginning\n",
    "'''\n",
    "s.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# I think this is the number of subhalos of the 0th halo.\n",
    "Nsubhalos = sf.data['fnsh'][0] # = 917\n",
    "print('Number of subhalos:', Nsubhalos)\n",
    "\n",
    "# this is the number of stars of each subhalo... as I see most of them are just DM (maybe gas) subhalos\n",
    "subhalosLenStars = sf.data['slty'][0:Nsubhalos,4]\n",
    "#print(subhalosLenStars)\n",
    "\n",
    "# select subhalos containing stars\n",
    "isubs, = np.where(subhalosLenStars > 0)\n",
    "print(isubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# so I need to mark particles of the dwarf galaxies and get their ID \n",
    "# (in order to get position and velocity at each timestep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s.calc_sf_indizes( sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.subhalo == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "istars, = numpy.where( (s.type == 4) & (s.halo == 0))\n",
    "(x, y, z), (vx, vy, vz), rxyz, rxy = get_cartesian_vectors(s, sf, istars)\n",
    "#xt, yt, zt = x[im], y[im], z[im]\n",
    "fig, (ax1, ax2) = pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.hist2d(1000*x, 1000*y, bins=401, norm=matplotlib.colors.LogNorm())\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.set_aspect('equal')\n",
    "ax2.hist2d(1000*rxy, 1000*z, bins=401, norm=matplotlib.colors.LogNorm())\n",
    "ax2.set_xlabel(\"R\")\n",
    "ax2.set_ylabel(\"z\")\n",
    "ax2.set_aspect('equal')\n",
    "fig.show()\n",
    "\n",
    "'''istars, = numpy.where( (s.type == 4) & (s.halo == 0) & (s.subhalo == 1))\n",
    "(x, y, z), (vx, vy, vz), rxyz, rxy = get_cartesian_vectors(s, sf, istars)\n",
    "#xt, yt, zt = x[im], y[im], z[im]\n",
    "fig, (ax1, ax2) = pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.hist2d(1000*x, 1000*y, bins=401, norm=matplotlib.colors.LogNorm())\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.set_aspect('equal')\n",
    "ax2.hist2d(1000*rxy, 1000*z, bins=401, norm=matplotlib.colors.LogNorm())\n",
    "ax2.set_xlabel(\"R\")\n",
    "ax2.set_ylabel(\"z\")\n",
    "ax2.set_aspect('equal')\n",
    "print(istars)\n",
    "print(s.id[istars])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids, ty, x, y, Z, vx, vy, vz, m = np.loadtxt('../data/level_5_halo_24_snapshot_63_data.txt',  \\\n",
    "                                             dtype=[('f0', '<i8'), ('f1', '<i8'), ('f2', '<f8'), \\\n",
    "                                                    ('f3', '<f8'), ('f4', '<f8'), ('f5', '<f8'), \\\n",
    "                                                    ('f6', '<f8'), ('f7', '<f8'), ('f8', '<f8')], unpack = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Rxy = np.sqrt(x**2 + y**2)\n",
    "rxyz = np.sqrt(x**2 + y**2 + z**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dens_3d(r0, r1, mass):\n",
    "    if r1 > r0:\n",
    "        rdiff = r1**3 - r0**3\n",
    "    else:\n",
    "        rdiff = r0**3 - r1**3        \n",
    "    vol = 4./3. * np.pi * rdiff\n",
    "    return vol\n",
    "\n",
    "def binning(r_vec, num = 50, scale = 'lin'):\n",
    "    r_min = np.min(r_vec)\n",
    "    r_max = np.max(r_vec)\n",
    "    if scale == 'lin':\n",
    "        r = np.linspace(r_min, r_max, num = num)\n",
    "    elif scale == 'log':\n",
    "        r = np.geomspace(r_min, r_max, num = num)\n",
    "    else:\n",
    "        sys.exit('Binning scale not yet defined.')\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_bins = binning(Rxy)\n",
    "bin_ind = np.digitize(Rxy, r_bins)\n",
    "z_bins = binning(Z)\n",
    "zbin_ind = np.digitize(Z, z_bins)\n",
    "mass_arr_r = []\n",
    "mass_arr_z = []\n",
    "for j in range (50):\n",
    "    mass_arr_r.append(np.sum(m[bin_ind == j+1]))\n",
    "for k in range (50):\n",
    "    mass_arr_z.append(np.sum(m[zbin_ind == k+1]))\n",
    "fig, (ax1, ax2) = pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "ax1.plot(1000*r_bins, mass_arr_r, 'k.')\n",
    "\n",
    "ax1.set_xlabel(\"R\")\n",
    "ax1.set_ylabel(\"mass\")\n",
    "#ax1.set_aspect('equal')\n",
    "ax2.hist2d(1000*rxy, 1000*z, bins=401, norm=matplotlib.colors.LogNorm())\n",
    "ax2.set_xlabel(\"R\")\n",
    "ax2.set_ylabel(\"z\")\n",
    "ax2.set_aspect('equal')\n",
    "fig.show()\n",
    "fig, (ax1, ax2) = pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "ax1.plot(1000*z_bins, mass_arr_z, 'k.')\n",
    "\n",
    "ax1.set_xlabel(\"z\")\n",
    "ax1.set_ylabel(\"mass\")\n",
    "#ax1.set_aspect('equal')\n",
    "ax2.hist2d(1000*rxy, 1000*z, bins=401, norm=matplotlib.colors.LogNorm())\n",
    "ax2.set_xlabel(\"R\")\n",
    "ax2.set_ylabel(\"z\")\n",
    "ax2.set_aspect('equal')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "istars, = numpy.where( (s.type == 4) & (s.halo == 0) & (s.r() > 10*s.galrad) )\n",
    "# check if exclusion of central galaxy is necessary\n",
    "(x, y, z), (vx, vy, vz), rxyz, rxy = get_cartesian_vectors(s, sf, istars)\n",
    "\n",
    "import sklearn.cluster as cl\n",
    "# n_cluster = 7 was better\n",
    "X = numpy.vstack((x,y,z)).T\n",
    "kmeans = cl.KMeans(n_clusters=9).fit(X)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(np.shape(centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = pyplot.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax1.plot(x, y, \"kD\", ms=1, alpha=0.1, c = 'yellow')\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"y\")\n",
    "ax1.scatter(centers[ :, 0], centers[:,1], c = 'red', zorder = 5)\n",
    "ax2.plot(x, z, \"kD\", ms=1, alpha=0.1)\n",
    "ax2.scatter(centers[:,0],centers[:,2], c='red', zorder = 5)\n",
    "ax2.set_xlabel(\"R\")\n",
    "ax2.set_ylabel(\"z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist, xedges, yedges = numpy.histogram2d(1000.*x[istars], 1000.*y[istars], bins = 100)\n",
    "#maxval = numpy.max(hist)\n",
    "maxindex = (-hist).argsort()\n",
    "maxhist = (-hist).sort()\n",
    "\n",
    "for i, item in enumerate(maxhist):\n",
    "    ind = hist.index(item)\n",
    "    targetval = 0.1*item\n",
    "    outinds = np.where(hist < targetval)\n",
    "    #foundinds = bisect()\n",
    "    \n",
    "    if i == 20: break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gadget_snap.plot_radmasspro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from areposnap.gadget_snap import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snapshot = snapnr\n",
    "snapbase=\"snapdir_\"\n",
    "snapbase2=\"snapshot_\"\n",
    "if (not (os.path.exists( \"%s/%s%03d\" % (snappath, snapbase, snapshot) ) or os.path.exists( \"%s/%s%03d.0\" % (snappath, snapbase, snapshot) ))) and (os.path.exists( \"%s/snapdir_%03d/%s%03d.0\" % (snappath, snapshot, snapbase, snapshot)) or os.path.exists( \"%s/snapdir_%03d/%s%03d.0.hdf5\" % (snappath, snapshot, snapbase, snapshot)) or os.path.exists( \"%s/snapdir_%03d/%s%03d.0.h5\" % (snappath, snapshot, snapbase, snapshot)) ):\n",
    "    snappath += \"/snapdir_%03d/\" % (snapshot)\n",
    "testshot = gadget_snapshot(\"%s%s%03d/%s%03d\" % (snappath, snapbase, snapnr, snapbase2, snapnr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testshot.plot_radmassprof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pynbody.load?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
